{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/0+WP93jlfMtXSvUMFjJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeadOnGames/Q-Learning-Frozen-Lake-Reinforcement-Learning/blob/main/Q_Learning_Frozen_Lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px2Vo4XRGV-y",
        "outputId": "afc80c23-a657-434b-c842-1335e5119603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gym[toy_text]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTGof3hLGg7h",
        "outputId": "1a52a5e9-d942-4338-b975-0bf736d04d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[toy_text] in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym[toy_text]) (1.21.6)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 31 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.11.0)\n",
            "Installing collected packages: pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.1.2\n",
            "    Uninstalling pygame-2.1.2:\n",
            "      Successfully uninstalled pygame-2.1.2\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN6Awzwl5_g3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"FrozenLake-v1\");"
      ],
      "metadata": {
        "id": "_C_8q13s6aUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e781d87-b420-4fe1-d4d2-063d4b6a065b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.8/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 10000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "#Epsilon Greedy Strategy\n",
        "exploration_rate = 1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.001"
      ],
      "metadata": {
        "id": "rmwxx3qr6cGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "\n",
        "q_table = np.zeros((state_space_size, action_space_size));\n",
        "print(q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU8Mb91m6eth",
        "outputId": "78bbce59-8bfc-4e25-f84d-1ab090b9ad72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "#Q-Learning Algorithnm\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    \n",
        "    done = False\n",
        "    rewards_current_episode = 0\n",
        "    \n",
        "    #Timestep within each episode\n",
        "    for step in range(max_steps_per_episode):\n",
        "        \n",
        "        #Exploration-exploitation trade off\n",
        "        exploration_rate_threshold = random.uniform(0,1);\n",
        "        if exploration_rate_threshold > exploration_rate:\n",
        "            action = np.argmax(q_table[state,:])\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        #Update Q-table for Q(s,a)\n",
        "        q_table[state, action] = q_table[state,action] * (1 - learning_rate) + learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
        "        #q_table[state, action] = q_table[state, action] + learning_rate * (reward + discount_rate * np.max(q_table[new_state,:]) - q_table[state, action])\n",
        "                             \n",
        "        state = new_state\n",
        "        rewards_current_episode += reward\n",
        "                             \n",
        "        if done == True:\n",
        "            break"
      ],
      "metadata": {
        "id": "A1RvhQlv6hln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    #Exploration rate decay\n",
        "    exploration_rate = min_exploration_rate + (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate * episode)\n",
        "    \n",
        "    rewards_all_episodes.append(rewards_current_episode)\n",
        "                                                             "
      ],
      "metadata": {
        "id": "0vQdMXwp6nIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    #Calculate and print the avergae reward per thousand episodes\n",
        "    rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes), num_episodes/10000)\n",
        "    count = 10000\n",
        "    print(\"*****Average reward per thousand episodes*****\\n\")\n",
        "    for r in rewards_per_thousand_episodes:\n",
        "        print(count, \": \", str(sum(r/10000)))\n",
        "        count += 10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2IlYgOl6uv7",
        "outputId": "3563b709-2d51-4465-f8bd-146b29245536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****Average reward per thousand episodes*****\n",
            "\n",
            "10000 :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print an updated Q-table\n",
        "print(\"\\n\\n*****Q-Table*****\\n\")\n",
        "print(q_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnJHCz_p868m",
        "outputId": "9d713256-a1df-4cab-ec0a-299f8cb34ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*****Q-Table*****\n",
            "\n",
            "[[0.57656118 0.5604676  0.55647621 0.55637809]\n",
            " [0.32771863 0.27577658 0.33724185 0.52473924]\n",
            " [0.46620801 0.44222372 0.44357288 0.47795434]\n",
            " [0.35545319 0.36714394 0.35301769 0.45899049]\n",
            " [0.59890511 0.39906052 0.43760313 0.42194436]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.43486018 0.24342429 0.29692748 0.19182954]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.32121725 0.52017932 0.40606843 0.61756752]\n",
            " [0.42283793 0.68302862 0.5636034  0.47316091]\n",
            " [0.61197302 0.37925607 0.43909513 0.41151429]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.43132727 0.43530457 0.7647102  0.55447989]\n",
            " [0.75214861 0.86933666 0.82617734 0.7437218 ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for episode in range(3):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    print(\"*****Episode \", episode+1, \"*****\\n\\n\\n\\n\")\n",
        "    time.sleep(1)\n",
        "    \n",
        "    for step in range(max_steps_per_episode):\n",
        "        clear_output(wait=True)\n",
        "        #env.render()\n",
        "        gym.make(\"FrozenLake-v1\", render_mode='human')\n",
        "        time.sleep(0.3)\n",
        "        \n",
        "        action = np.argmax(q_table[state,:])\n",
        "        \n",
        "        #Take the best action\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            clear_output(wait=True)\n",
        "            gym.make(\"FrozenLake-v1\", render_mode='human')\n",
        "            if reward == 1:\n",
        "                print(\"*****You reached the goal*****\")\n",
        "                time.sleep(3)\n",
        "            else:\n",
        "                print(\"*****You fell through a hole*****\")\n",
        "                time.sleep(3)\n",
        "            clear_output(wait=True)\n",
        "            break\n",
        "            \n",
        "        state = new_state\n",
        "        \n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JwC9tvX8-cF",
        "outputId": "464a489d-ace9-4c6a-c277-8db4a31c404b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****You fell through a hole*****\n"
          ]
        }
      ]
    }
  ]
}